import os
import django

# 1. Django ì„¤ì • íŒŒì¼ ì§€ì •
os.environ.setdefault("DJANGO_SETTINGS_MODULE", "navis_server.settings")
# 2. Django ì„¤ì • ë¡œë“œ
django.setup()

from django.conf import settings
from huggingface_hub import snapshot_download
from peft import PeftModel, PeftConfig
from transformers import AutoModelForCausalLM, AutoTokenizer

# 1. ì €ì¥í•  ë¡œì»¬ ê²½ë¡œ ì„¤ì •
local_adapter_path = os.path.join(
    settings.BASE_DIR, "core", "ai_models", "saved_adapter"
)
peft_model_id = "bini7890/navis-polyglot-lora"

# í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
os.makedirs(local_adapter_path, exist_ok=True)

# 2. Hugging Faceì—ì„œ í•´ë‹¹ ê²½ë¡œë¡œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
print(f"ğŸ“‚ [AI] ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘... -> {local_adapter_path}")
snapshot_download(
    repo_id=peft_model_id,
    local_dir=local_adapter_path,
    local_dir_use_symlinks=False,  # ì‹¤ì œ íŒŒì¼ì„ ì €ì¥
)

# 3. ë¡œì»¬ ê²½ë¡œì—ì„œ Config ë¶ˆëŸ¬ì˜¤ê¸°
config = PeftConfig.from_pretrained(local_adapter_path)

# 4. Base ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
model = AutoModelForCausalLM.from_pretrained(
    config.base_model_name_or_path, device_map="auto"
)

# 5. LoRA ì–´ëŒ‘í„° ì¥ì°©
model = PeftModel.from_pretrained(model, local_adapter_path)
tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)

print("âœ… [AI] ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
