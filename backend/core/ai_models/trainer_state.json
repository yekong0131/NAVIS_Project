{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 160,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.032,
      "grad_norm": 0.46000605821609497,
      "learning_rate": 0.0,
      "loss": 2.351,
      "step": 1
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.5264430046081543,
      "learning_rate": 4e-05,
      "loss": 2.3885,
      "step": 2
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.48836952447891235,
      "learning_rate": 8e-05,
      "loss": 2.3475,
      "step": 3
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.4980064630508423,
      "learning_rate": 0.00012,
      "loss": 2.294,
      "step": 4
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.517979085445404,
      "learning_rate": 0.00016,
      "loss": 2.1879,
      "step": 5
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.5856232047080994,
      "learning_rate": 0.0002,
      "loss": 2.1038,
      "step": 6
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.660783052444458,
      "learning_rate": 0.00019997946042345127,
      "loss": 2.0919,
      "step": 7
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.6920714974403381,
      "learning_rate": 0.00019991785013128923,
      "loss": 2.0294,
      "step": 8
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.7455495595932007,
      "learning_rate": 0.0001998151944325001,
      "loss": 2.1131,
      "step": 9
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.8549830913543701,
      "learning_rate": 0.00019967153549717553,
      "loss": 1.9772,
      "step": 10
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.6888390183448792,
      "learning_rate": 0.00019948693233918952,
      "loss": 1.8816,
      "step": 11
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.8459411263465881,
      "learning_rate": 0.00019926146079195594,
      "loss": 1.7014,
      "step": 12
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.6750297546386719,
      "learning_rate": 0.0001989952134772769,
      "loss": 1.6644,
      "step": 13
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.741176187992096,
      "learning_rate": 0.00019868829976729443,
      "loss": 1.6995,
      "step": 14
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6096524596214294,
      "learning_rate": 0.00019834084573956128,
      "loss": 1.7081,
      "step": 15
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.6579205989837646,
      "learning_rate": 0.00019795299412524945,
      "loss": 1.4862,
      "step": 16
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.658065676689148,
      "learning_rate": 0.00019752490425051743,
      "loss": 1.6329,
      "step": 17
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.672368586063385,
      "learning_rate": 0.00019705675197106016,
      "loss": 1.4076,
      "step": 18
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.8475104570388794,
      "learning_rate": 0.00019654872959986937,
      "loss": 1.479,
      "step": 19
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.7969569563865662,
      "learning_rate": 0.0001960010458282326,
      "loss": 1.4873,
      "step": 20
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.8360161185264587,
      "learning_rate": 0.00019541392564000488,
      "loss": 1.5381,
      "step": 21
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.8738769888877869,
      "learning_rate": 0.00019478761021918728,
      "loss": 1.3612,
      "step": 22
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.831279993057251,
      "learning_rate": 0.00019412235685085035,
      "loss": 1.4481,
      "step": 23
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.8216042518615723,
      "learning_rate": 0.00019341843881544372,
      "loss": 1.4151,
      "step": 24
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.8240220546722412,
      "learning_rate": 0.00019267614527653488,
      "loss": 1.2642,
      "step": 25
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.8474595546722412,
      "learning_rate": 0.00019189578116202307,
      "loss": 1.324,
      "step": 26
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.7332546710968018,
      "learning_rate": 0.00019107766703887764,
      "loss": 1.2984,
      "step": 27
    },
    {
      "epoch": 0.896,
      "grad_norm": 1.0687212944030762,
      "learning_rate": 0.00019022213898145176,
      "loss": 1.4261,
      "step": 28
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.7208275198936462,
      "learning_rate": 0.00018932954843342591,
      "loss": 1.2442,
      "step": 29
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.7110693454742432,
      "learning_rate": 0.00018840026206343784,
      "loss": 1.2813,
      "step": 30
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.7500786781311035,
      "learning_rate": 0.00018743466161445823,
      "loss": 1.2482,
      "step": 31
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.2262847423553467,
      "learning_rate": 0.00018643314374697378,
      "loss": 1.2877,
      "step": 32
    },
    {
      "epoch": 1.032,
      "grad_norm": 0.790463387966156,
      "learning_rate": 0.00018539611987604258,
      "loss": 1.2638,
      "step": 33
    },
    {
      "epoch": 1.064,
      "grad_norm": 0.7262259721755981,
      "learning_rate": 0.00018432401600228823,
      "loss": 1.2293,
      "step": 34
    },
    {
      "epoch": 1.096,
      "grad_norm": 0.6798783540725708,
      "learning_rate": 0.0001832172725369024,
      "loss": 1.1779,
      "step": 35
    },
    {
      "epoch": 1.1280000000000001,
      "grad_norm": 0.5691868662834167,
      "learning_rate": 0.00018207634412072764,
      "loss": 1.2436,
      "step": 36
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.660399854183197,
      "learning_rate": 0.00018090169943749476,
      "loss": 1.1009,
      "step": 37
    },
    {
      "epoch": 1.192,
      "grad_norm": 0.7267545461654663,
      "learning_rate": 0.0001796938210212915,
      "loss": 1.2177,
      "step": 38
    },
    {
      "epoch": 1.224,
      "grad_norm": 0.6273480653762817,
      "learning_rate": 0.00017845320505834175,
      "loss": 1.2312,
      "step": 39
    },
    {
      "epoch": 1.256,
      "grad_norm": 0.6125715970993042,
      "learning_rate": 0.0001771803611831762,
      "loss": 1.1793,
      "step": 40
    },
    {
      "epoch": 1.288,
      "grad_norm": 0.7999732494354248,
      "learning_rate": 0.0001758758122692791,
      "loss": 1.1081,
      "step": 41
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.8714655041694641,
      "learning_rate": 0.00017454009421429597,
      "loss": 1.1844,
      "step": 42
    },
    {
      "epoch": 1.3519999999999999,
      "grad_norm": 0.9786911606788635,
      "learning_rate": 0.00017317375571989158,
      "loss": 1.137,
      "step": 43
    },
    {
      "epoch": 1.384,
      "grad_norm": 0.7625291347503662,
      "learning_rate": 0.00017177735806634789,
      "loss": 1.0926,
      "step": 44
    },
    {
      "epoch": 1.416,
      "grad_norm": 0.7437846064567566,
      "learning_rate": 0.00017035147488199482,
      "loss": 1.2096,
      "step": 45
    },
    {
      "epoch": 1.448,
      "grad_norm": 0.8406349420547485,
      "learning_rate": 0.00016889669190756868,
      "loss": 1.0657,
      "step": 46
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.8019277453422546,
      "learning_rate": 0.00016741360675559473,
      "loss": 1.152,
      "step": 47
    },
    {
      "epoch": 1.512,
      "grad_norm": 1.1709500551223755,
      "learning_rate": 0.00016590282866489319,
      "loss": 1.1865,
      "step": 48
    },
    {
      "epoch": 1.544,
      "grad_norm": 0.6034492254257202,
      "learning_rate": 0.00016436497825030884,
      "loss": 1.1443,
      "step": 49
    },
    {
      "epoch": 1.576,
      "grad_norm": 0.7655647397041321,
      "learning_rate": 0.00016280068724776797,
      "loss": 1.168,
      "step": 50
    },
    {
      "epoch": 1.608,
      "grad_norm": 0.7603801488876343,
      "learning_rate": 0.0001612105982547663,
      "loss": 0.9987,
      "step": 51
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 0.8903982043266296,
      "learning_rate": 0.0001595953644663957,
      "loss": 1.1443,
      "step": 52
    },
    {
      "epoch": 1.6720000000000002,
      "grad_norm": 0.799018919467926,
      "learning_rate": 0.000157955649407017,
      "loss": 1.0822,
      "step": 53
    },
    {
      "epoch": 1.704,
      "grad_norm": 0.8669829964637756,
      "learning_rate": 0.00015629212665768978,
      "loss": 1.0474,
      "step": 54
    },
    {
      "epoch": 1.736,
      "grad_norm": 1.0278578996658325,
      "learning_rate": 0.00015460547957947104,
      "loss": 1.1006,
      "step": 55
    },
    {
      "epoch": 1.768,
      "grad_norm": 0.7697038650512695,
      "learning_rate": 0.00015289640103269625,
      "loss": 1.1661,
      "step": 56
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.804629921913147,
      "learning_rate": 0.00015116559309235825,
      "loss": 1.0521,
      "step": 57
    },
    {
      "epoch": 1.8319999999999999,
      "grad_norm": 0.6673991680145264,
      "learning_rate": 0.0001494137667597006,
      "loss": 1.129,
      "step": 58
    },
    {
      "epoch": 1.8639999999999999,
      "grad_norm": 0.8840517401695251,
      "learning_rate": 0.00014764164167014451,
      "loss": 1.2258,
      "step": 59
    },
    {
      "epoch": 1.896,
      "grad_norm": 0.6789606809616089,
      "learning_rate": 0.00014584994579766865,
      "loss": 1.0335,
      "step": 60
    },
    {
      "epoch": 1.928,
      "grad_norm": 0.8511112332344055,
      "learning_rate": 0.00014403941515576344,
      "loss": 1.0036,
      "step": 61
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.8288161158561707,
      "learning_rate": 0.0001422107934950832,
      "loss": 1.1183,
      "step": 62
    },
    {
      "epoch": 1.992,
      "grad_norm": 0.6912955641746521,
      "learning_rate": 0.00014036483199791948,
      "loss": 1.0524,
      "step": 63
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.7626192569732666,
      "learning_rate": 0.0001385022889696218,
      "loss": 1.0379,
      "step": 64
    },
    {
      "epoch": 2.032,
      "grad_norm": 0.7858489155769348,
      "learning_rate": 0.00013662392952709228,
      "loss": 1.0989,
      "step": 65
    },
    {
      "epoch": 2.064,
      "grad_norm": 0.6688437461853027,
      "learning_rate": 0.00013473052528448201,
      "loss": 1.0272,
      "step": 66
    },
    {
      "epoch": 2.096,
      "grad_norm": 0.6677895188331604,
      "learning_rate": 0.00013282285403621864,
      "loss": 0.9839,
      "step": 67
    },
    {
      "epoch": 2.128,
      "grad_norm": 0.6807495951652527,
      "learning_rate": 0.00013090169943749476,
      "loss": 0.9655,
      "step": 68
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.6628571152687073,
      "learning_rate": 0.00012896785068234926,
      "loss": 1.0375,
      "step": 69
    },
    {
      "epoch": 2.192,
      "grad_norm": 0.6576874852180481,
      "learning_rate": 0.00012702210217947288,
      "loss": 1.0846,
      "step": 70
    },
    {
      "epoch": 2.224,
      "grad_norm": 1.2381625175476074,
      "learning_rate": 0.00012506525322587207,
      "loss": 1.1746,
      "step": 71
    },
    {
      "epoch": 2.2560000000000002,
      "grad_norm": 0.7833693027496338,
      "learning_rate": 0.00012309810767852433,
      "loss": 1.0009,
      "step": 72
    },
    {
      "epoch": 2.288,
      "grad_norm": 0.8850983381271362,
      "learning_rate": 0.00012112147362416076,
      "loss": 0.9566,
      "step": 73
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.7133627533912659,
      "learning_rate": 0.00011913616304731063,
      "loss": 0.9911,
      "step": 74
    },
    {
      "epoch": 2.352,
      "grad_norm": 0.788513720035553,
      "learning_rate": 0.00011714299149674537,
      "loss": 1.0881,
      "step": 75
    },
    {
      "epoch": 2.384,
      "grad_norm": 0.734225332736969,
      "learning_rate": 0.00011514277775045768,
      "loss": 0.9615,
      "step": 76
    },
    {
      "epoch": 2.416,
      "grad_norm": 0.9474225044250488,
      "learning_rate": 0.00011313634347931466,
      "loss": 0.8503,
      "step": 77
    },
    {
      "epoch": 2.448,
      "grad_norm": 1.0904335975646973,
      "learning_rate": 0.00011112451290952237,
      "loss": 1.0733,
      "step": 78
    },
    {
      "epoch": 2.48,
      "grad_norm": 1.0582197904586792,
      "learning_rate": 0.00010910811248404065,
      "loss": 1.0267,
      "step": 79
    },
    {
      "epoch": 2.512,
      "grad_norm": 1.2009952068328857,
      "learning_rate": 0.0001070879705230873,
      "loss": 1.0566,
      "step": 80
    },
    {
      "epoch": 2.544,
      "grad_norm": 0.8986459374427795,
      "learning_rate": 0.00010506491688387127,
      "loss": 1.0063,
      "step": 81
    },
    {
      "epoch": 2.576,
      "grad_norm": 1.0770595073699951,
      "learning_rate": 0.0001030397826196943,
      "loss": 1.062,
      "step": 82
    },
    {
      "epoch": 2.608,
      "grad_norm": 1.2151190042495728,
      "learning_rate": 0.00010101339963856111,
      "loss": 1.0801,
      "step": 83
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.884968101978302,
      "learning_rate": 9.898660036143893e-05,
      "loss": 1.0165,
      "step": 84
    },
    {
      "epoch": 2.672,
      "grad_norm": 0.7733784914016724,
      "learning_rate": 9.696021738030575e-05,
      "loss": 0.9246,
      "step": 85
    },
    {
      "epoch": 2.7039999999999997,
      "grad_norm": 0.8586066365242004,
      "learning_rate": 9.493508311612874e-05,
      "loss": 1.0224,
      "step": 86
    },
    {
      "epoch": 2.7359999999999998,
      "grad_norm": 0.8151996731758118,
      "learning_rate": 9.291202947691271e-05,
      "loss": 0.9473,
      "step": 87
    },
    {
      "epoch": 2.768,
      "grad_norm": 0.9198101758956909,
      "learning_rate": 9.089188751595936e-05,
      "loss": 0.9672,
      "step": 88
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.7049457430839539,
      "learning_rate": 8.887548709047764e-05,
      "loss": 1.0126,
      "step": 89
    },
    {
      "epoch": 2.832,
      "grad_norm": 0.7933474779129028,
      "learning_rate": 8.686365652068535e-05,
      "loss": 0.9518,
      "step": 90
    },
    {
      "epoch": 2.864,
      "grad_norm": 0.8719174861907959,
      "learning_rate": 8.485722224954237e-05,
      "loss": 0.9695,
      "step": 91
    },
    {
      "epoch": 2.896,
      "grad_norm": 1.0428694486618042,
      "learning_rate": 8.285700850325467e-05,
      "loss": 1.0428,
      "step": 92
    },
    {
      "epoch": 2.928,
      "grad_norm": 1.2028414011001587,
      "learning_rate": 8.086383695268938e-05,
      "loss": 0.9096,
      "step": 93
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.9742500185966492,
      "learning_rate": 7.887852637583926e-05,
      "loss": 0.95,
      "step": 94
    },
    {
      "epoch": 2.992,
      "grad_norm": 1.0775812864303589,
      "learning_rate": 7.690189232147566e-05,
      "loss": 0.907,
      "step": 95
    },
    {
      "epoch": 3.0,
      "grad_norm": 1.2555203437805176,
      "learning_rate": 7.493474677412794e-05,
      "loss": 0.9718,
      "step": 96
    },
    {
      "epoch": 3.032,
      "grad_norm": 0.877409815788269,
      "learning_rate": 7.297789782052717e-05,
      "loss": 0.9118,
      "step": 97
    },
    {
      "epoch": 3.064,
      "grad_norm": 0.9437864422798157,
      "learning_rate": 7.10321493176508e-05,
      "loss": 1.0131,
      "step": 98
    },
    {
      "epoch": 3.096,
      "grad_norm": 1.0028635263442993,
      "learning_rate": 6.909830056250527e-05,
      "loss": 0.869,
      "step": 99
    },
    {
      "epoch": 3.128,
      "grad_norm": 1.0210472345352173,
      "learning_rate": 6.717714596378137e-05,
      "loss": 0.872,
      "step": 100
    },
    {
      "epoch": 3.16,
      "grad_norm": 0.7884249091148376,
      "learning_rate": 6.526947471551798e-05,
      "loss": 0.9851,
      "step": 101
    },
    {
      "epoch": 3.192,
      "grad_norm": 0.8603675365447998,
      "learning_rate": 6.337607047290774e-05,
      "loss": 0.9349,
      "step": 102
    },
    {
      "epoch": 3.224,
      "grad_norm": 1.1805888414382935,
      "learning_rate": 6.149771103037821e-05,
      "loss": 0.8902,
      "step": 103
    },
    {
      "epoch": 3.2560000000000002,
      "grad_norm": 0.7999697923660278,
      "learning_rate": 5.9635168002080564e-05,
      "loss": 0.8947,
      "step": 104
    },
    {
      "epoch": 3.288,
      "grad_norm": 0.8820247054100037,
      "learning_rate": 5.7789206504916816e-05,
      "loss": 0.9832,
      "step": 105
    },
    {
      "epoch": 3.32,
      "grad_norm": 1.000715732574463,
      "learning_rate": 5.596058484423656e-05,
      "loss": 0.8772,
      "step": 106
    },
    {
      "epoch": 3.352,
      "grad_norm": 1.158879041671753,
      "learning_rate": 5.415005420233141e-05,
      "loss": 0.9139,
      "step": 107
    },
    {
      "epoch": 3.384,
      "grad_norm": 1.2830514907836914,
      "learning_rate": 5.2358358329855516e-05,
      "loss": 1.0121,
      "step": 108
    },
    {
      "epoch": 3.416,
      "grad_norm": 1.047689437866211,
      "learning_rate": 5.058623324029944e-05,
      "loss": 1.0728,
      "step": 109
    },
    {
      "epoch": 3.448,
      "grad_norm": 0.8555915951728821,
      "learning_rate": 4.8834406907641784e-05,
      "loss": 0.9622,
      "step": 110
    },
    {
      "epoch": 3.48,
      "grad_norm": 0.8251607418060303,
      "learning_rate": 4.710359896730379e-05,
      "loss": 0.9332,
      "step": 111
    },
    {
      "epoch": 3.512,
      "grad_norm": 0.7688488960266113,
      "learning_rate": 4.539452042052901e-05,
      "loss": 0.905,
      "step": 112
    },
    {
      "epoch": 3.544,
      "grad_norm": 1.0600653886795044,
      "learning_rate": 4.3707873342310254e-05,
      "loss": 0.9596,
      "step": 113
    },
    {
      "epoch": 3.576,
      "grad_norm": 0.9345765113830566,
      "learning_rate": 4.204435059298303e-05,
      "loss": 0.7848,
      "step": 114
    },
    {
      "epoch": 3.608,
      "grad_norm": 0.8874698877334595,
      "learning_rate": 4.040463553360431e-05,
      "loss": 0.9922,
      "step": 115
    },
    {
      "epoch": 3.64,
      "grad_norm": 1.0413541793823242,
      "learning_rate": 3.878940174523371e-05,
      "loss": 0.991,
      "step": 116
    },
    {
      "epoch": 3.672,
      "grad_norm": 0.841600775718689,
      "learning_rate": 3.719931275223205e-05,
      "loss": 0.973,
      "step": 117
    },
    {
      "epoch": 3.7039999999999997,
      "grad_norm": 1.0180416107177734,
      "learning_rate": 3.5635021749691166e-05,
      "loss": 0.9301,
      "step": 118
    },
    {
      "epoch": 3.7359999999999998,
      "grad_norm": 0.878265917301178,
      "learning_rate": 3.4097171335106824e-05,
      "loss": 0.9087,
      "step": 119
    },
    {
      "epoch": 3.768,
      "grad_norm": 1.0703816413879395,
      "learning_rate": 3.258639324440527e-05,
      "loss": 1.0586,
      "step": 120
    },
    {
      "epoch": 3.8,
      "grad_norm": 1.3235714435577393,
      "learning_rate": 3.110330809243135e-05,
      "loss": 0.8819,
      "step": 121
    },
    {
      "epoch": 3.832,
      "grad_norm": 0.8955113887786865,
      "learning_rate": 2.96485251180052e-05,
      "loss": 0.8812,
      "step": 122
    },
    {
      "epoch": 3.864,
      "grad_norm": 0.7814155220985413,
      "learning_rate": 2.8222641933652117e-05,
      "loss": 0.907,
      "step": 123
    },
    {
      "epoch": 3.896,
      "grad_norm": 0.8685378432273865,
      "learning_rate": 2.6826244280108437e-05,
      "loss": 0.9083,
      "step": 124
    },
    {
      "epoch": 3.928,
      "grad_norm": 0.7920073866844177,
      "learning_rate": 2.5459905785704042e-05,
      "loss": 0.8608,
      "step": 125
    },
    {
      "epoch": 3.96,
      "grad_norm": 0.9900991916656494,
      "learning_rate": 2.4124187730720903e-05,
      "loss": 0.8707,
      "step": 126
    },
    {
      "epoch": 3.992,
      "grad_norm": 0.9611151814460754,
      "learning_rate": 2.2819638816823786e-05,
      "loss": 0.9019,
      "step": 127
    },
    {
      "epoch": 4.0,
      "grad_norm": 2.7018327713012695,
      "learning_rate": 2.154679494165829e-05,
      "loss": 0.9921,
      "step": 128
    },
    {
      "epoch": 4.032,
      "grad_norm": 0.9672101736068726,
      "learning_rate": 2.0306178978708514e-05,
      "loss": 0.842,
      "step": 129
    },
    {
      "epoch": 4.064,
      "grad_norm": 0.991051971912384,
      "learning_rate": 1.9098300562505266e-05,
      "loss": 0.9407,
      "step": 130
    },
    {
      "epoch": 4.096,
      "grad_norm": 1.021444320678711,
      "learning_rate": 1.7923655879272393e-05,
      "loss": 0.8263,
      "step": 131
    },
    {
      "epoch": 4.128,
      "grad_norm": 0.7898416519165039,
      "learning_rate": 1.6782727463097624e-05,
      "loss": 0.9165,
      "step": 132
    },
    {
      "epoch": 4.16,
      "grad_norm": 0.9284013509750366,
      "learning_rate": 1.5675983997711795e-05,
      "loss": 0.9074,
      "step": 133
    },
    {
      "epoch": 4.192,
      "grad_norm": 0.9455322623252869,
      "learning_rate": 1.4603880123957447e-05,
      "loss": 0.9533,
      "step": 134
    },
    {
      "epoch": 4.224,
      "grad_norm": 0.9767546653747559,
      "learning_rate": 1.356685625302625e-05,
      "loss": 0.879,
      "step": 135
    },
    {
      "epoch": 4.256,
      "grad_norm": 0.9138842225074768,
      "learning_rate": 1.2565338385541792e-05,
      "loss": 0.8823,
      "step": 136
    },
    {
      "epoch": 4.288,
      "grad_norm": 0.9718768000602722,
      "learning_rate": 1.1599737936562149e-05,
      "loss": 0.9133,
      "step": 137
    },
    {
      "epoch": 4.32,
      "grad_norm": 1.6349009275436401,
      "learning_rate": 1.0670451566574102e-05,
      "loss": 0.982,
      "step": 138
    },
    {
      "epoch": 4.352,
      "grad_norm": 1.3780320882797241,
      "learning_rate": 9.777861018548251e-06,
      "loss": 1.0841,
      "step": 139
    },
    {
      "epoch": 4.384,
      "grad_norm": 0.9061114192008972,
      "learning_rate": 8.92233296112236e-06,
      "loss": 0.828,
      "step": 140
    },
    {
      "epoch": 4.416,
      "grad_norm": 1.0191107988357544,
      "learning_rate": 8.10421883797694e-06,
      "loss": 0.9197,
      "step": 141
    },
    {
      "epoch": 4.448,
      "grad_norm": 0.8513447046279907,
      "learning_rate": 7.32385472346514e-06,
      "loss": 0.9128,
      "step": 142
    },
    {
      "epoch": 4.48,
      "grad_norm": 0.8565051555633545,
      "learning_rate": 6.581561184556295e-06,
      "loss": 0.9297,
      "step": 143
    },
    {
      "epoch": 4.5120000000000005,
      "grad_norm": 0.9930277466773987,
      "learning_rate": 5.87764314914967e-06,
      "loss": 1.0207,
      "step": 144
    },
    {
      "epoch": 4.5440000000000005,
      "grad_norm": 0.7730083465576172,
      "learning_rate": 5.212389780812732e-06,
      "loss": 0.8523,
      "step": 145
    },
    {
      "epoch": 4.576,
      "grad_norm": 1.2915059328079224,
      "learning_rate": 4.586074359995119e-06,
      "loss": 0.7388,
      "step": 146
    },
    {
      "epoch": 4.608,
      "grad_norm": 1.0283924341201782,
      "learning_rate": 3.998954171767422e-06,
      "loss": 0.8363,
      "step": 147
    },
    {
      "epoch": 4.64,
      "grad_norm": 0.8620097637176514,
      "learning_rate": 3.451270400130646e-06,
      "loss": 0.835,
      "step": 148
    },
    {
      "epoch": 4.672,
      "grad_norm": 1.032400369644165,
      "learning_rate": 2.943248028939838e-06,
      "loss": 0.8179,
      "step": 149
    },
    {
      "epoch": 4.704,
      "grad_norm": 0.9072723388671875,
      "learning_rate": 2.4750957494826033e-06,
      "loss": 0.9179,
      "step": 150
    },
    {
      "epoch": 4.736,
      "grad_norm": 0.8310653567314148,
      "learning_rate": 2.0470058747505516e-06,
      "loss": 0.921,
      "step": 151
    },
    {
      "epoch": 4.768,
      "grad_norm": 1.1176347732543945,
      "learning_rate": 1.6591542604387445e-06,
      "loss": 1.0024,
      "step": 152
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.8301257491111755,
      "learning_rate": 1.3117002327055927e-06,
      "loss": 0.9162,
      "step": 153
    },
    {
      "epoch": 4.832,
      "grad_norm": 1.7841126918792725,
      "learning_rate": 1.004786522723089e-06,
      "loss": 0.7268,
      "step": 154
    },
    {
      "epoch": 4.864,
      "grad_norm": 0.8803450465202332,
      "learning_rate": 7.385392080440534e-07,
      "loss": 0.8525,
      "step": 155
    },
    {
      "epoch": 4.896,
      "grad_norm": 0.8580681085586548,
      "learning_rate": 5.130676608104845e-07,
      "loss": 0.9171,
      "step": 156
    },
    {
      "epoch": 4.928,
      "grad_norm": 0.9649163484573364,
      "learning_rate": 3.2846450282447703e-07,
      "loss": 0.979,
      "step": 157
    },
    {
      "epoch": 4.96,
      "grad_norm": 0.9261929988861084,
      "learning_rate": 1.8480556749991274e-07,
      "loss": 0.8801,
      "step": 158
    },
    {
      "epoch": 4.992,
      "grad_norm": 0.8975027799606323,
      "learning_rate": 8.214986871076802e-08,
      "loss": 0.8189,
      "step": 159
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.6055283546447754,
      "learning_rate": 2.0539576548717076e-08,
      "loss": 0.8033,
      "step": 160
    },
    {
      "epoch": 5.0,
      "step": 160,
      "total_flos": 1.9512864270434304e+16,
      "train_loss": 1.1309791035950183,
      "train_runtime": 1333.9421,
      "train_samples_per_second": 3.748,
      "train_steps_per_second": 0.12
    }
  ],
  "logging_steps": 1,
  "max_steps": 160,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.9512864270434304e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
