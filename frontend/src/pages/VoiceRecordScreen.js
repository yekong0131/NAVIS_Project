import React, { useState, useRef, useEffect } from 'react';
import axios from 'axios';

// API ì£¼ì†Œ
const API_BASE_URL = process.env.REACT_APP_API_URL || 'http://localhost:8000/api';

const VoiceRecordScreen = ({ onNavigate }) => {
  const [isRecording, setIsRecording] = useState(false);
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [volumeLevel, setVolumeLevel] = useState(0); // 0 ~ 100

  const mediaRecorderRef = useRef(null);
  const audioChunksRef = useRef([]);
  
  // ì˜¤ë””ì˜¤ ì‹œê°í™”ìš© Ref
  const audioContextRef = useRef(null);
  const analyserRef = useRef(null);
  const dataArrayRef = useRef(null);
  const animationFrameRef = useRef(null);

  // ì»´í¬ë„ŒíŠ¸ í•´ì œ ì‹œ ì •ë¦¬
  useEffect(() => {
    return () => {
        cancelAnimationFrame(animationFrameRef.current);
        if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
            audioContextRef.current.close();
        }
    };
  }, []);

  const getSupportedMimeType = () => {
    const types = ['audio/webm;codecs=opus', 'audio/webm', 'audio/mp4', 'audio/ogg;codecs=opus'];
    for (const type of types) {
      if (MediaRecorder.isTypeSupported(type)) return type;
    }
    return '';
  };

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      
      // ----------------------------------------------------
      // ì˜¤ë””ì˜¤ ì‹œê°í™” (ë³¼ë¥¨ ë¯¸í„°) ì„¤ì •
      // ----------------------------------------------------
      if (!audioContextRef.current) {
          audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();
      }
      const audioCtx = audioContextRef.current;

      // ë¸Œë¼ìš°ì € ì •ì±…ìœ¼ë¡œ ì¤‘ì§€ëœ ì˜¤ë””ì˜¤ ì—”ì§„ ê¹¨ìš°ê¸°
      if (audioCtx.state === 'suspended') {
          await audioCtx.resume();
      }

      const analyser = audioCtx.createAnalyser();
      analyser.fftSize = 256;
      
      const source = audioCtx.createMediaStreamSource(stream);
      source.connect(analyser);
      
      analyserRef.current = analyser;
      const bufferLength = analyser.frequencyBinCount;
      dataArrayRef.current = new Uint8Array(bufferLength);
      
      detectVolume();
      // ----------------------------------------------------

      const mimeType = getSupportedMimeType();
      const options = mimeType ? { mimeType } : {};
      mediaRecorderRef.current = new MediaRecorder(stream, options);
      audioChunksRef.current = [];

      mediaRecorderRef.current.ondataavailable = (event) => {
        if (event.data.size > 0) audioChunksRef.current.push(event.data);
      };

      mediaRecorderRef.current.onstop = handleStop;
      mediaRecorderRef.current.start(100);
      setIsRecording(true);

    } catch (err) {
      console.error("ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨:", err);
      alert("ë§ˆì´í¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¶Œí•œ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.");
    }
  };

  // ì‹¤ì‹œê°„ ë³¼ë¥¨ ê°ì§€
  const detectVolume = () => {
      if (!analyserRef.current || !dataArrayRef.current) return;

      analyserRef.current.getByteFrequencyData(dataArrayRef.current);
      
      let sum = 0;
      const length = dataArrayRef.current.length;
      for (let i = 0; i < length; i++) {
          sum += dataArrayRef.current[i];
      }
      const average = sum / length;
      
      // ì‹œê°í™” íš¨ê³¼ë¥¼ ìœ„í•´ ê°’ì„ ì¢€ í‚¤ì›€ (ìµœëŒ€ 100)
      const normalizedVolume = Math.min(100, average * 2.5); 
      setVolumeLevel(normalizedVolume);

      animationFrameRef.current = requestAnimationFrame(detectVolume);
  };

  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
      setVolumeLevel(0);
      cancelAnimationFrame(animationFrameRef.current);
      
      if (mediaRecorderRef.current.stream) {
          mediaRecorderRef.current.stream.getTracks().forEach(track => track.stop());
      }
    }
  };

  const handleStop = async () => {
    setTimeout(async () => {
        if (audioChunksRef.current.length === 0) return;
        setIsAnalyzing(true);
        
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
        const audioFile = new File([audioBlob], "recording.webm", { type: "audio/webm" });
        
        const formData = new FormData();
        formData.append('audio', audioFile);

        try {
            const response = await axios.post(`${API_BASE_URL}/diaries/analyze/`, formData, {
                headers: { 'Content-Type': 'multipart/form-data' }
            });
            if (onNavigate) onNavigate('write', response.data);

        } catch (error) {
            console.error("ë¶„ì„ ì‹¤íŒ¨:", error);
            const msg = error.response?.data?.error || "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.";
            alert(msg);
            setIsAnalyzing(false);
        }
    }, 500);
  };

  return (
    <div className="fixed inset-0 bg-slate-900 flex justify-center items-center z-50 font-sans">
        <div className="relative w-full max-w-[420px] h-full bg-slate-900 flex flex-col text-white shadow-2xl overflow-hidden">
            
            {/* ë‹«ê¸° ë²„íŠ¼ */}
            <div className="absolute top-0 right-0 p-6 pt-12 z-[60]">
                <button 
                    onClick={() => {
                        if (isRecording) stopRecording();
                        onNavigate('diary');
                    }} 
                    className="p-4 text-gray-400 hover:text-white cursor-pointer"
                >
                    <span className="text-2xl font-bold">âœ•</span>
                </button>
            </div>

            {/* ë©”ì¸ ì˜ì—­ */}
            <div className="flex-1 flex flex-col items-center justify-center -mt-10">
                {isAnalyzing ? (
                    <div className="flex flex-col items-center animate-pulse">
                        <span className="text-5xl mb-6">ğŸ§ </span>
                        <h2 className="text-xl font-bold text-indigo-300">ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...</h2>
                        <p className="text-sm text-gray-400 mt-2">ì¡°ê³¼ ë‚´ìš©ì„ ì •ë¦¬í•˜ê³  ìˆì–´ìš”</p>
                    </div>
                ) : (
                    <>
                        {/* ë§ˆì´í¬ ë²„íŠ¼ & ì‹œê°í™” íš¨ê³¼ */}
                        <div className={`relative w-40 h-40 rounded-full flex items-center justify-center transition-all duration-200 ${isRecording ? 'bg-gray-800' : 'bg-gray-800'}`}>
                            
                            {/* ë³¼ë¥¨ì— ë”°ë¼ ì»¤ì§€ëŠ” ì´ˆë¡ìƒ‰ ì•„ìš°ë¼ */}
                            {isRecording && (
                                <div 
                                    className="absolute inset-0 rounded-full bg-green-500/30 blur-xl transition-all duration-75"
                                    style={{ transform: `scale(${1 + volumeLevel / 40})` }}
                                ></div>
                            )}

                            <button 
                                onClick={isRecording ? stopRecording : startRecording}
                                className={`relative z-10 w-28 h-28 rounded-full flex items-center justify-center shadow-2xl transition-all duration-300 ${isRecording ? 'bg-red-500 hover:bg-red-600' : 'bg-indigo-600 hover:bg-indigo-500'}`}
                            >
                                <span className="text-5xl">{isRecording ? 'â¬›' : 'ğŸ¤'}</span>
                            </button>
                        </div>
                        
                        {/* ë³¼ë¥¨ ë§‰ëŒ€ ê·¸ë˜í”„ */}
                        <div className="w-64 h-1.5 bg-gray-700 rounded-full mt-8 overflow-hidden">
                            <div 
                                className={`h-full transition-all duration-75 ease-out ${volumeLevel > 0 ? 'bg-green-400 shadow-[0_0_10px_#4ade80]' : 'bg-transparent'}`}
                                style={{ width: `${volumeLevel}%` }}
                            ></div>
                        </div>

                        <h2 className="text-2xl font-bold mt-6 mb-2">
                            {isRecording ? "ë“£ê³  ìˆì–´ìš”..." : "í„°ì¹˜í•˜ì—¬ ë§í•˜ê¸°"}
                        </h2>
                        
                        {/* â­ ë‹¤ì‹œ ëŒì•„ì˜¨ ì˜ˆì‹œ ë¬¸êµ¬! */}
                        {!isRecording && (
                            <div className="bg-white/5 rounded-2xl p-5 mx-8 mt-4 border border-white/10 animate-fade-in-up">
                                <p className="text-gray-300 text-sm text-center leading-relaxed">
                                    <span className="text-indigo-300 font-bold">"ì˜¤ëŠ˜ ì‚¼ë´‰í•­ì—ì„œ ì­ˆê¾¸ë¯¸ 20ë§ˆë¦¬ ì¡ì•˜ì–´"</span>
                                    <br/>ì²˜ëŸ¼ ë§í•´ë³´ì„¸ìš”.
                                </p>
                            </div>
                        )}

                        {/* ë…¹ìŒ ì¤‘ì¼ ë•Œ ìƒíƒœ ë©”ì‹œì§€ */}
                        {isRecording && (
                             <p className="text-sm text-gray-400 mt-2 animate-pulse">
                                {volumeLevel < 5 ? "ì¢€ ë” í¬ê²Œ ë§ì”€í•´ì£¼ì„¸ìš” ğŸ“¢" : "ëª©ì†Œë¦¬ê°€ ì˜ ë“¤ë¦½ë‹ˆë‹¤! ğŸ‘Œ"}
                             </p>
                        )}
                    </>
                )}
            </div>
        </div>
    </div>
  );
};

export default VoiceRecordScreen;